{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e265b95c-c5d1-442a-a900-5e591aa3bab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
    "import sys\n",
    "import assemblyai as aai\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "# Suppress HTTP request logs\n",
    "logging.getLogger(\"urllib3\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"requests\").setLevel(logging.WARNING)\n",
    "\n",
    "sys.path.append(r'home/y2c/2024-25c-fai2-adsai-group-group_11_2c/Task_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8c910c4-f3f8-4684-83c7-1b5bb699ba19",
   "metadata": {},
   "outputs": [],
   "source": [
    "### HELPER FUNCTIONS ###\n",
    "\n",
    "# Loading model and tokenizer\n",
    "def loading_model_tokenizer(model_path='../Task_5/DistilBERT/dbert_iter4', tokenizer_name=\"distilbert-base-uncased\"):\n",
    "    # I had to load the model with tensorflow since I had saved it using tf and not transformers\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    # Since I did not change the tokenizer in the training by adding custom tokens or changing the vocabulary size, it is fine to use the base one from Transformers.\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "# Changed task 2 for returning a dataframe without saving it into a csv file\n",
    "def transcribe_audio_to_df(audio_file_path):\n",
    "    # Set your API key\n",
    "    aai.settings.api_key = \"fb2df8accbcb4f38ba02666862cd6216\"\n",
    "\n",
    "    # Transcribe audio\n",
    "    transcriber = aai.Transcriber()\n",
    "    transcript = transcriber.transcribe(audio_file_path)\n",
    "\n",
    "    # Extract sentences into a list of dicts\n",
    "    data = []\n",
    "    for i, sentence in enumerate(transcript.get_sentences(), 1):\n",
    "        data.append({\n",
    "            \"Text\": sentence.text,\n",
    "            \"Start Time (s)\": round(sentence.start / 1000, 2),\n",
    "            \"End Time (s)\": round(sentence.end / 1000, 2),\n",
    "        })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "df = transcribe_audio_to_df('test.mp3')\n",
    "\n",
    "def tokenize_texts(texts):\n",
    "    return tokenizer(list(texts), truncation=True, padding=True, return_tensors=\"tf\", max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d7973b00-b076-4971-85a4-29746ab9e755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(model, audio_file_path):\n",
    "\n",
    "    valid_models = ['dbert', 'droberta', 'lstm', 'rnn', 'naive_bayes', 'logistic_regression']\n",
    "    unique_labels = ['neutral', 'surprise', 'disgust', 'sadness', 'happiness', 'anger', 'fear']\n",
    "\n",
    "    # Initialize and fit the LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(unique_labels)\n",
    "    \n",
    "    # Check if the passed model is valid\n",
    "    if model not in valid_models:\n",
    "        raise ValueError(f\"Invalid model! Expected one of {valid_models}, but got '{model}'\")\n",
    "\n",
    "    ### 2. TRANSCRIBING AUDIO DATA (TASK 2) ###\n",
    "    print(\"Exctracting the transcript of the audio...\")\n",
    "    #df = transcribe_audio_to_df(audio_file_data)\n",
    "\n",
    "    ### 3. Loading the models based on input\n",
    "    if model == 'dbert':\n",
    "        print(f\"Initializing {model}...\")\n",
    "        model, tokenizer = loading_model_tokenizer('../Task_5/DistilBERT/dbert_iter4')\n",
    "\n",
    "        df_tokenized = tokenize_texts(df['Text'].tolist())\n",
    "\n",
    "        # Prepare the tokenized input as a dictionary for the model\n",
    "        inputs = {\n",
    "            'input_ids': df_tokenized['input_ids'],\n",
    "            'attention_mask': df_tokenized['attention_mask']\n",
    "        }\n",
    "\n",
    "        print('Getting the predictions...')\n",
    "\n",
    "        # Get predictions from the model\n",
    "        predictions = model.predict(inputs)\n",
    "        \n",
    "        # Extract logits from predictions\n",
    "        logits = predictions['logits']  # Now we can directly access the logits\n",
    "\n",
    "        # Get the predicted class by finding the maximum logit in each row\n",
    "        results = np.argmax(logits, axis=-1)\n",
    "\n",
    "        # Assuming 'results' is the array of predicted labels from your model\n",
    "        decoded_emotions = label_encoder.inverse_transform(results)\n",
    "        \n",
    "        # Map the results to emotion names\n",
    "        df['Emotion'] = decoded_emotions\n",
    "        return df\n",
    "        \n",
    "    elif model == 'droberta':\n",
    "        print(f\"Initializing {model}...\")\n",
    "        model, tokenizer = loading_model_tokenizer('../Task_5/DistillRoberta/droberta_iter2')\n",
    "        model = tf.keras.models.load_model('../Task_5/DistillRoberta/droberta_iter2')\n",
    "\n",
    "        df_tokenized = tokenize_texts(df['Text'].tolist())\n",
    "\n",
    "        # Prepare the tokenized input as a dictionary for the model\n",
    "        inputs = {\n",
    "            'input_ids': df_tokenized['input_ids'],\n",
    "            'attention_mask': df_tokenized['attention_mask'],\n",
    "            'token_type_ids': None  # or tf.zeros_like(inputs['input_ids']) if required\n",
    "        }\n",
    "    \n",
    "        print('Getting the predictions...')\n",
    "        \n",
    "        # Get predictions from the model\n",
    "        predictions = model.predict(inputs)\n",
    "        \n",
    "        # Extract logits from predictions\n",
    "        logits = predictions['logits']  # Now we can directly access the logits\n",
    "\n",
    "        # Get the predicted class by finding the maximum logit in each row\n",
    "        results = np.argmax(logits, axis=-1)\n",
    "\n",
    "        # Assuming 'results' is the array of predicted labels from your model\n",
    "        decoded_emotions = label_encoder.inverse_transform(results)\n",
    "        \n",
    "        # Map the results to emotion names\n",
    "        df['Emotion'] = decoded_emotions\n",
    "        return df\n",
    "\n",
    "    elif model == 'lstm':\n",
    "        print(f\"Initializing {model}...\")\n",
    "        model, tokenizer = loading_model_tokenizer(model)\n",
    "\n",
    "    elif model == 'rnn':\n",
    "        print(f\"Initializing {model}...\")\n",
    "        model, tokenizer = loading_model_tokenizer(model)\n",
    "\n",
    "    elif model == 'naive_bayes':\n",
    "        print(f\"Initializing {model}...\")\n",
    "        model, tokenizer = loading_model_tokenizer(model)\n",
    "\n",
    "    else:\n",
    "        print(f\"Initializing {model}...\")\n",
    "        model, tokenizer = loading_model_tokenizer(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b13aa8c-8007-4680-a48d-899f95b79332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exctracting the transcript of the audio...\n",
      "Initializing droberta...\n",
      "Getting the predictions...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: (<class 'dict'> containing {\"<class 'str'>\"} keys and {\"<class 'NoneType'>\", \"<class 'tensorflow.python.framework.ops.EagerTensor'>\"} values), <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdroberta\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest.mp3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "Cell \u001b[0;32mIn[62], line 65\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(model, audio_file_path)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGetting the predictions...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Get predictions from the model\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Extract logits from predictions\u001b[39;00m\n\u001b[1;32m     68\u001b[0m logits \u001b[38;5;241m=\u001b[39m predictions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Now we can directly access the logits\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/tf_keras/src/engine/data_adapter.py:1102\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1099\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mcls\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ALL_ADAPTER_CLS \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mcan_handle(x, y)]\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m adapter_cls:\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;66;03m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to find data adapter that can handle input: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1104\u001b[0m             _type_name(x), _type_name(y)\n\u001b[1;32m   1105\u001b[0m         )\n\u001b[1;32m   1106\u001b[0m     )\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(adapter_cls) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData adapters should be mutually exclusive for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1110\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhandling inputs. Found multiple adapters \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m to handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(adapter_cls, _type_name(x), _type_name(y))\n\u001b[1;32m   1112\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'dict'> containing {\"<class 'str'>\"} keys and {\"<class 'NoneType'>\", \"<class 'tensorflow.python.framework.ops.EagerTensor'>\"} values), <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "df = pipeline('droberta', 'test.mp3')\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
