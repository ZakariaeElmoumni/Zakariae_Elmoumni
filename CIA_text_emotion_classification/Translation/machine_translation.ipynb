{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01d21223-042a-44c5-8b56-38bc21952c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: TensorFlow version 2.19.0 available.\n",
      "2025-04-05 12:31:03.690722: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-05 12:31:03.705438: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743856263.720070 1209061 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743856263.724621 1209061 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743856263.737553 1209061 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743856263.737566 1209061 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743856263.737568 1209061 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743856263.737569 1209061 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-05 12:31:03.741614: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-05 12:31:06.605757: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "I0000 00:00:1743856266.606064 1209061 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46672 MB memory:  -> device: 0, name: NVIDIA RTX 6000 Ada Generation, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "All model checkpoint layers were used when initializing TFMBartForConditionalGeneration.\n",
      "\n",
      "All the layers of TFMBartForConditionalGeneration were initialized from the model checkpoint at model_en_nl.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMBartForConditionalGeneration for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFMBartForConditionalGeneration.\n",
      "\n",
      "All the layers of TFMBartForConditionalGeneration were initialized from the model checkpoint at model_nl_en.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMBartForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import tensorflow as tf\n",
    "from transformers import MBart50Tokenizer, TFTrainingArguments, TFMBartForConditionalGeneration, DataCollatorForSeq2Seq, create_optimizer\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # For progress bar\n",
    "\n",
    "en_nl_model = TFMBartForConditionalGeneration.from_pretrained(\"model_en_nl\")\n",
    "nl_en_model = TFMBartForConditionalGeneration.from_pretrained(\"model_nl_en\")\n",
    "\n",
    "# Load the tokenizers\n",
    "tokenizer = MBart50Tokenizer.from_pretrained(\"model_en_nl\")\n",
    "tokenizer_nl_en = MBart50Tokenizer.from_pretrained(\"model_nl_en\")\n",
    "\n",
    "# 7. Function to translate from Dutch to English\n",
    "def translate_nl_to_en(text):\n",
    "    # Set source language to Dutch\n",
    "    tokenizer_nl_en.src_lang = \"nl_XX\"\n",
    "    \n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer_nl_en(text, return_tensors=\"tf\", max_length=128, truncation=True)\n",
    "    \n",
    "    # Generate translation with forced English BOS token\n",
    "    output_ids = model_nl_en.generate(\n",
    "        **inputs,\n",
    "        forced_bos_token_id=tokenizer_nl_en.lang_code_to_id[\"en_XX\"]  # Force English as output\n",
    "    )\n",
    "    \n",
    "    # Decode the output\n",
    "    translation = tokenizer_nl_en.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return translation\n",
    "\n",
    "# 8. Function to perform round-trip translation\n",
    "def round_trip_translation(df, text_column, en_nl_model, nl_en_model, batch_size=16):\n",
    "\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    dutch_translations = []\n",
    "    back_translations = []\n",
    "\n",
    "    texts = df[text_column].astype(str).tolist()\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        \n",
    "        # === ENGLISH → DUTCH ===\n",
    "        tokenizer.src_lang = \"en_XX\"\n",
    "        inputs_en = tokenizer(batch_texts, return_tensors=\"tf\", padding=True, truncation=True, max_length=128)\n",
    "        outputs_nl = en_nl_model.generate(\n",
    "            **inputs_en,\n",
    "            forced_bos_token_id=tokenizer.lang_code_to_id[\"nl_XX\"]\n",
    "        )\n",
    "        batch_nl = tokenizer.batch_decode(outputs_nl, skip_special_tokens=True)\n",
    "        dutch_translations.extend(batch_nl)\n",
    "        \n",
    "        # === DUTCH → ENGLISH ===\n",
    "        tokenizer_nl_en.src_lang = \"nl_XX\"\n",
    "        inputs_nl = tokenizer_nl_en(batch_nl, return_tensors=\"tf\", padding=True, truncation=True, max_length=128)\n",
    "        outputs_en = nl_en_model.generate(\n",
    "            **inputs_nl,\n",
    "            forced_bos_token_id=tokenizer_nl_en.lang_code_to_id[\"en_XX\"]\n",
    "        )\n",
    "        batch_back = tokenizer_nl_en.batch_decode(outputs_en, skip_special_tokens=True)\n",
    "        back_translations.extend(batch_back)\n",
    "\n",
    "    result_df[\"Translation\"] = dutch_translations\n",
    "    result_df[\"English Translation\"] = back_translations\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ede16427-cf78-41af-9589-59a3666b4d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [1:27:43<00:00, 526.34s/it]\n"
     ]
    }
   ],
   "source": [
    "assembly_ai = pd.read_excel('../Task_3/STT_AssemblyAI.xlsx')\n",
    "\n",
    "round_translation = round_trip_translation(assembly_ai, 'Corrected', en_nl_model, nl_en_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ea5d1dc-4ee6-4c21-a201-ec0049e82b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_translation.to_csv('translation_scored.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "y2c",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
